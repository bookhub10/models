import os
import sys
import inspect
import pickle
import json
import threading
import traceback
import numpy as np
import pandas as pd
import requests 
from flask import Flask, request, jsonify
from tensorflow.keras.models import load_model
import warnings
import subprocess

# Suppress TensorFlow and other library warnings
warnings.filterwarnings("ignore")
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' 

# --- Path Setup for External Modules ---
try:
    current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
    root_dir = os.path.dirname(current_dir)
    if root_dir not in sys.path:
        sys.path.append(root_dir)
    
    # Import necessary functions from the external training script
    from linux_model import add_technical_indicators, scale_features#, train_rnn_model_main 
    
    print("‚úÖ External model functions loaded successfully.")
except ImportError as e:
    print(f"‚ùå FATAL: Cannot import from models.model. Error: {e}")
    sys.exit(1)
except Exception as e:
    print(f"‚ùå FATAL: An unexpected error occurred during import: {e}")
    sys.exit(1)

# --- Configuration & Global State ---

class Config:
    MODEL_PATH = 'models/gru_bot_best_M5.h5' 
    SCALER_PATH = 'models/scaler.pkl'
    SEQUENCE_LENGTH = 100
    
    # --- ‚¨áÔ∏è [‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà] ‚¨áÔ∏è ---
    # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà "‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à" ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡∏¢‡∏≠‡∏°‡πÄ‡∏ó‡∏£‡∏î
    # (‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÅ‡∏Ñ‡πà 40% (0.4) ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô HOLD)
    PREDICTION_THRESHOLD = 0.4 # ‚¨ÖÔ∏è ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏π‡∏ô‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô 0.45 ‡∏´‡∏£‡∏∑‡∏≠ 0.55)

app = Flask(__name__)
rnn_model = None
scaler = None

# üõë ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (15 Features)
REQUIRED_FEATURES = [
    'open', 'high', 'low', 'close', 'tick_volume', 
    'SMA_10', 'SMA_50', 'Momentum_1', 'High_Low',
    'M30_RSI', 'H1_MA_Trend',
    'ATR_14',
    'RSI_Overbought', # ‚¨ÖÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°
    'RSI_Oversold',   # ‚¨ÖÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°
    'SMA_Cross'       # ‚¨ÖÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°
]

account_status = {
    'bot_status': 'STOPPED', 
    'balance': 0.0,
    'equity': 0.0,
    'margin_free': 0.0,
    'open_trades': 0,
    'last_signal': 'NONE'
}

# --- Download Model & Scaler from GitHub --- 
def download_model_assets():
    """Download model and scaler from GitHub."""
    GITHUB_FILES = {
        'gru_model': {
            'url': 'https://raw.githubusercontent.com/bookhub10/models/main/models/gru_bot_best_M5.h5',
            'filename': Config.MODEL_PATH
        },
        'scaler': {
            'url': 'https://raw.githubusercontent.com/bookhub10/models/main/models/scaler.pkl',
            'filename': Config.SCALER_PATH
        }
    }

    os.makedirs(os.path.dirname(Config.MODEL_PATH), exist_ok=True)

    for file_info in GITHUB_FILES.values():
        url = file_info['url']
        output_path = file_info['filename']

        try:
            print(f"‚¨áÔ∏è Downloading {output_path} from GitHub...")
            response = requests.get(url)
            response.raise_for_status()

            with open(output_path, 'wb') as f:
                f.write(response.content)

            print(f"‚úÖ Downloaded: {output_path}")
        except Exception as e:
            print(f"‚ùå Failed to download {output_path}: {e}")
            raise

# --- Download Python Files from GitHub ---
def download_python_files():
    """Download the main Python scripts from GitHub."""
    GITHUB_PYTHON_FILES = {
        'linux_api': {
            'url': 'https://raw.githubusercontent.com/bookhub10/models/main/linux_api.py',
            'filename': 'linux_api.py'
        },
        'linux_telegram': {
            'url': 'https://raw.githubusercontent.com/bookhub10/models/main/linux_telegram.py',
            'filename': 'linux_telegram.py'
        },
        # Assuming linux_model.py is in the root directory for simplicity.
        # If it's in a different path, adjust filename here.
        'linux_model': { 
            'url': 'https://raw.githubusercontent.com/bookhub10/models/main/linux_model.py',
            'filename': 'linux_model.py'
        }
    }

    success = True
    for file_info in GITHUB_PYTHON_FILES.values():
        url = file_info['url']
        output_path = file_info['filename']

        try:
            print(f"‚¨áÔ∏è Downloading {output_path} from GitHub...")
            response = requests.get(url)
            response.raise_for_status()

            with open(output_path, 'wb') as f:
                f.write(response.content)

            print(f"‚úÖ Downloaded: {output_path}")
        except Exception as e:
            print(f"‚ùå Failed to download {output_path}: {e}")
            success = False
            # ‡πÑ‡∏°‡πà throw error ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏∑‡πà‡∏ô‡∏ï‡πà‡∏≠
    return success

# --- Asset Management ---

def load_assets():
    """Load the Keras H5 model and MinMaxScaler."""
    global rnn_model, scaler
    print("--- Attempting to load Model and Scaler ---")
    try:
        rnn_model = load_model(Config.MODEL_PATH)
        with open(Config.SCALER_PATH, 'rb') as f:
            scaler = pickle.load(f)
        
        if hasattr(scaler, 'n_features_in_'):
            print(f"DEBUG: Scaler expects {scaler.n_features_in_} features.")
            
        print("‚úÖ Model and Scaler loaded successfully.")
        return True
    except FileNotFoundError:
        print(f"‚ùå Error: Model or Scaler file not found. Check paths: {Config.MODEL_PATH}, {Config.SCALER_PATH}")
    except Exception as e:
        print(f"‚ùå Critical Error loading assets: {e}")
        traceback.print_exc()
    
    rnn_model = None
    scaler = None
    return False

# --- JSON Parsing Helper (Robust against MQL output issues) ---

def parse_mql_json(req):
    """Helper to safely parse JSON from MQL5 (which might contain trailing NULs)."""
    if req.data:
        try:
            # Decode using utf-8 and strip any non-printable chars
            raw_data = req.data.decode('utf-8', errors='ignore').strip('\x00').strip()
            return json.loads(raw_data)
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON Decode Error: {e}")
            print(f"Raw data snippet (first 200 chars): {raw_data[:200]}")
            return None
    return None

# --- Core Prediction Logic ---

# --- üõë [‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ] (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 3-Class) üõë ---
def preprocess_and_predict(raw_data):
    """
    Processes 15 features, runs 3-CLASS prediction, and returns signal/prob/atr.
    """
    global rnn_model, scaler
    
    # 1. ‡πÅ‡∏õ‡∏•‡∏á JSON (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    try:
        df_m5 = pd.DataFrame(raw_data['m5_data'])
        df_m30 = pd.DataFrame(raw_data['m30_data'])
        df_h1 = pd.DataFrame(raw_data['h1_data'])
        # (‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏õ‡∏•‡∏á time index ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
        df_m5['time'] = pd.to_datetime(df_m5['time'], unit='s')
        df_m5.set_index('time', inplace=True)
        df_m30['time'] = pd.to_datetime(df_m30['time'], unit='s')
        df_m30.set_index('time', inplace=True)
        df_m30 = df_m30[['close']] 
        df_h1['time'] = pd.to_datetime(df_h1['time'], unit='s')
        df_h1.set_index('time', inplace=True)
        df_h1 = df_h1[['close']] 
    except Exception as e:
        raise ValueError(f"Failed to parse Multi-Timeframe data. Error: {e}")

    # 2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô 15-feature (‡∏à‡∏≤‡∏Å linux_model.py)
    df_features = add_technical_indicators(df_m5, df_m30, df_h1)
    
    # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    if len(df_features) < Config.SEQUENCE_LENGTH:
        raise ValueError(f"Not enough valid bars after merging TFs ({len(df_features)} bars), expected at least {Config.SEQUENCE_LENGTH}.")

    # 4. ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ ATR ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    latest_atr = df_features['ATR_14'].iloc[-1]

    # 5. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Sequence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Scaling (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    df_for_scaling = df_features.iloc[-Config.SEQUENCE_LENGTH:].copy() 
    
    # 6. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 15 ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (‡πÉ‡∏ä‡πâ List ‡πÉ‡∏´‡∏°‡πà)
    df_for_scaling_trimmed = df_for_scaling[REQUIRED_FEATURES]
    
    # 7. Scaling (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    try:
        _, test_scaled, _ = scale_features(
            df_for_scaling_trimmed, test_df=None, scaler=scaler
        )
    except Exception as e:
        raise ValueError(f"Scaling failed (check feature count: {len(df_for_scaling_trimmed.columns)}). Error: {e}")

    # 8. Prepare Sequence & Predict (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    X_pred_data = test_scaled.values 
    X_pred = np.array([X_pred_data]) 
    
    # 9. üõë [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] üõë Predict ‡πÅ‡∏ö‡∏ö 3-Class
    # prediction ‡∏à‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ: [[0.7 (HOLD), 0.2 (BUY), 0.1 (SELL)]]
    prediction_array = rnn_model.predict(X_pred, verbose=0)[0]
    
    # 10. üõë [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] üõë Determine Signal (‡∏´‡∏≤ Class ‡∏ó‡∏µ‡πà‡∏ä‡∏ô‡∏∞)
    
    # ‡∏î‡∏∂‡∏á Class ‡∏ó‡∏µ‡πà‡∏°‡∏µ % ‡∏ä‡∏ô‡∏∞‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (0, 1, ‡∏´‡∏£‡∏∑‡∏≠ 2)
    predicted_class = np.argmax(prediction_array) 
    
    # ‡∏î‡∏∂‡∏á % ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á Class ‡∏ó‡∏µ‡πà‡∏ä‡∏ô‡∏∞
    probability = np.max(prediction_array) 
    
    signal = 'NONE' # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    if predicted_class == 1: # 1 = BUY
        signal = 'BUY'
    elif predicted_class == 2: # 2 = SELL
        signal = 'SELL'
    elif predicted_class == 0: # 0 = HOLD
        signal = 'HOLD' # ‚¨ÖÔ∏è ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÉ‡∏´‡∏°‡πà
    
    account_status['last_signal'] = signal
        
    # 11. ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ ATR (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
    # (‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á ATR ‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ)
    return signal, probability, latest_atr

# --- API Endpoints ---

# üÜï ‡πÄ‡∏û‡∏¥‡πà‡∏° Endpoint /status ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ MT5 EA ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
@app.route('/status', methods=['GET']) 
def get_status():
    """Endpoint for MT5 EA to check the bot's current status and performance."""
    global account_status, rnn_model, scaler
    try:
        current_status = account_status.copy()
        current_status['model_loaded'] = (rnn_model is not None)
        current_status['scaler_loaded'] = (scaler is not None)
        return jsonify(current_status), 200
    except Exception as e:
        print(f"‚ùå Error fetching status: {e}")
        return jsonify({'bot_status': 'ERROR', 'message': f'Server internal error: {str(e)}'}), 500

# --- üõë [‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà Endpoint ‡∏ô‡∏µ‡πâ] (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 3-Class) üõë ---
@app.route('/predict', methods=['POST']) 
def predict_signal():
    if rnn_model is None or scaler is None:
        return jsonify({'signal': 'ERROR', 'probability': 0.0, 'message': 'Model not loaded.'}), 503
    if account_status['bot_status'] != 'RUNNING':
        return jsonify({'signal': 'NONE', 'probability': 0.0, 'message': f"Bot is {account_status['bot_status']}."}), 200

    try:
        data = parse_mql_json(request)
        if data is None:
            return jsonify({'signal': 'ERROR', 'probability': 0.0, 'message': 'Invalid JSON data received.'}), 400
        
        signal, probability, atr = preprocess_and_predict(data)
        
        # --- ‚¨áÔ∏è [‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà] ‚¨áÔ∏è ---
        # üõë "‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à" üõë
        # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (probability) ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå (0.50)...
        if probability < Config.PREDICTION_THRESHOLD:
            # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô HOLD (‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ö‡∏≠‡∏Å BUY/SELL)
            signal = 'HOLD' 
        # --- ‚¨ÜÔ∏è [‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà] ‚¨ÜÔ∏è ---
        
        return jsonify({
            'signal': signal, # ‚¨ÖÔ∏è ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡πá‡∏ô "HOLD" ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß
            'probability': float(probability),
            'atr': float(atr),
            'message': 'Prediction successful.'
        }), 200
        
    except ValueError as ve:
        print(f"‚ùå Prediction validation error: {ve}")
        return jsonify({'signal': 'ERROR', 'probability': 0.0, 'message': str(ve)}), 400
    except Exception as e:
        print(f"‚ùå CRITICAL ERROR in /predict: {e}")
        traceback.print_exc()
        return jsonify({'signal': 'ERROR', 'probability': 0.0, 'message': 'Internal Server Error.'}), 500

@app.route('/update_status', methods=['POST']) 
def update_status():
    """Endpoint for MT5 to send updated account status and trade alerts."""
    try:
        # üõë FIX: ‡πÉ‡∏ä‡πâ parse_mql_json ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Null bytes ‡πÅ‡∏•‡∏∞ JSON format
        data = parse_mql_json(request)
        
        if data is None:
             return jsonify({'status': 'ERROR', 'message': 'Invalid JSON data received.'}), 400
             
        account_status.update({
            'balance': data.get('balance', 0.0),
            'equity': data.get('equity', 0.0),
            'margin_free': data.get('margin_free', 0.0),
            'open_trades': data.get('open_trades', 0),
        })

        alert_message = data.get('alert_message')
        if alert_message and alert_message.strip() != '': # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö alert_message
            print(f"üö® MQL ALERT: {alert_message}")

        return jsonify({'status': 'SUCCESS'})
    except Exception as e:
        print(f"‚ùå update_status exception: {e}")
        traceback.print_exc()
        return jsonify({'status': 'ERROR', 'message': str(e)}), 500

@app.route('/command', methods=['POST'])
def execute_command():
    """Endpoint for Telegram Bot or external system to send START/STOP commands."""
    try:
        command = request.json.get('command')
        
        if command == 'START':
            account_status['bot_status'] = 'RUNNING'
            return jsonify({'status': 'SUCCESS', 'message': 'Bot set to RUNNING.'})
        
        elif command == 'STOP':
            account_status['bot_status'] = 'STOPPED'
            return jsonify({'status': 'SUCCESS', 'message': 'Bot set to STOPPED.'})
        
        else:
            return jsonify({'status': 'FAIL', 'message': 'Invalid command.'}), 400

    except Exception as e:
        return jsonify({'status': 'ERROR', 'message': str(e)}), 500

@app.route('/retrain', methods=['POST'])
def retrain_model_async():
    if account_status['bot_status'] != 'STOPPED':
        return jsonify({'status': 'FAIL', 'message': '‚ùå This command requires the bot to be STOPPED.'}), 400

    try:
        # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler ‡∏à‡∏≤‡∏Å Google Drive
        download_model_assets()

        # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏≤ memory
        if load_assets():
            return jsonify({'status': 'SUCCESS', 'message': '‚úÖ Retraining completed and model loaded.'}), 200
        else:
            return jsonify({'status': 'FAIL', 'message': '‚ö†Ô∏è Model or scaler could not be loaded after download.'}), 500

    except Exception as e:
        print(f"‚ùå Error in retrain_model_async: {e}")
        traceback.print_exc()
        return jsonify({'status': 'FAIL', 'message': f'Error during retraining: {str(e)}'}), 500

@app.route('/update_ea', methods=['POST'])
def update_expert_advisor():
    """
    [NEW VERSION] Downloads the EA and creates a trigger file.
    The actual compile is handled by linux_compiler.py (GUI Watcher).
    """
    EA_URL = 'https://raw.githubusercontent.com/bookhub10/models/main/linux_OBot.mq5' 
    EA_PATH = "/home/hp/.mt5/drive_c/Program Files/MetaTrader 5/MQL5/Experts/OBotTrading.mq5"
    TRIGGER_FILE = "/home/hp/Downloads/bot/COMPILE_NOW.trigger" # ‚¨ÖÔ∏è ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì

    try:
        # 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå EA
        print(f"‚¨áÔ∏è Downloading new EA from {EA_URL}...")
        response = requests.get(EA_URL)
        response.raise_for_status()
        with open(EA_PATH, 'wb') as f:
            f.write(response.content)
        print("‚úÖ EA Downloaded.")

        # 2. üõë [THE FIX] üõë
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Trigger ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ "Watcher" ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        with open(TRIGGER_FILE, 'w') as f:
            f.write('triggered') # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏•‡∏á‡πÑ‡∏õ
        print(f"‚úÖ Trigger file created at {TRIGGER_FILE}")

        return jsonify({
            'status': 'SUCCESS', 
            'message': f'‚úÖ EA Downloaded. Compile trigger issued to GUI watcher.'
        }), 200

    except Exception as e:
        print(f"‚ùå Error in /update_ea: {e}")
        traceback.print_exc()
        return jsonify({'status': 'FAIL', 'message': f'Error during EA update: {str(e)}'}), 500

@app.route('/restart', methods=['POST'])
def restart_service():
    """Endpoint to restart the service via systemd."""
    try:
        # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤
        # (‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ sudoers ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)
        command = ["sudo", "/bin/systemctl", "restart", "obot_api.service"]
        command2 = ["sudo", "/bin/systemctl", "restart", "obot_telegram.service"]
        command3 = ["sudo", "/bin/systemctl", "restart", "obot_mt5.service"]

        subprocess.run(command3)
        subprocess.run(command2)
        subprocess.run(command)
        
        return jsonify({'status': 'SUCCESS', 'message': 'The service restart command issued.'}), 200
    except Exception as e:
        print(f"‚ùå Error in /restart: {e}")
        return jsonify({'status': 'FAIL', 'message': str(e)}), 500


# üÜï ‡πÄ‡∏û‡∏¥‡πà‡∏° Endpoint /fix
@app.route('/fix', methods=['POST'])
def fix_system_files():
    """Downloads updated Python scripts and reloads model assets."""
    # 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Python ‡πÉ‡∏´‡∏°‡πà
    python_downloaded = download_python_files()

    # 2. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ scaler ‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£ retrain)
    try:
        download_model_assets()
    except Exception as e:
        return jsonify({'status': 'FAIL', 'message': f'‚ùå Failed to download model assets: {str(e)}. Python files may be updated.'}), 500
        
    # 3. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Scaler ‡πÄ‡∏Ç‡πâ‡∏≤ memory
    assets_loaded = load_assets()
    
    message = "‚úÖ System files and assets updated successfully."
    
    if not python_downloaded:
        message = "‚ö†Ô∏è Python files update failed for one or more files. Assets reloaded."

    if not assets_loaded:
        return jsonify({'status': 'FAIL', 'message': '‚ö†Ô∏è Assets downloaded but failed to load into memory. System files updated. **Please manually restart the server.**'}), 500

    return jsonify({
        'status': 'SUCCESS', 
        'message': f'{message} **Requires Server Restart** for new Python files to take effect.'
    }), 200

# --- Server Run ---
if __name__ == '__main__':
    if load_assets():
        print("üí° NOTE: Remember to start the separate telegram_bot.py script.")
        app.run(host='0.0.0.0', port=5000)
